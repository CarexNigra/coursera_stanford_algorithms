{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Graph Search\n",
    "\n",
    "Motivation:\n",
    "1. check is a physical network (telecommunication, transport) is connected (get from anywhaere to anywhere)\n",
    "2. or non-physical network is connected: co-staring actors\n",
    "    * the nodes correspond to actors and actresses, \n",
    "    * an edge between two nodes, if they played a role in a common movie. \n",
    "    * an undirected graph,\n",
    "    * So versions of this movie network you should be able to find publicly available on the web, and there's lots of fun questions you can ask about the movie network. \n",
    "        * what's the minimum number of hops ( = edges = movies that two people both played a role in) from one actor to another actor, \n",
    "        * so perhaps the most famous statistic that's been thought about with the movie is the Bacon Number. \n",
    "            * So this refers to the fairly ubiquitous actor Kevin Bacon, \n",
    "            * the question the Bacon Number of an actor is defined as the minimum number of hops you need in this movie graph to get to Kevin Bacon. \n",
    "            *  Bacon Number is fundamentally not just about any path, but actually shortest paths, the minimum number of edges you need to traverse to get from one actor to Kevin Bacon. \n",
    "3. shortest paths to go from 1 point to another = driving direction\n",
    "4. formulate a plan of how to get from an initial state to some goal state: \n",
    "    * sudoku\n",
    "        * directed graph\n",
    "        * nodes = partially comleted puzzles\n",
    "        * edge = directed, 1 previousy empty cell is filled with one number\n",
    "    * robotic hand manipulated to grab an object\n",
    "5. computing connectivity information about graphs = connected components = pieces of graphs\n",
    "    * undirected graphs = easy clustering euristics derives from connectivity\n",
    "    * directed graphs = more subtile = structure of the web\n",
    "     \n",
    "A lot of different approaches to searching a graph. Here we focus on two\n",
    "* Breadth first search\n",
    "* Depth first search\n",
    "  \n",
    "Goals: \n",
    "* We define a source (starting vertex) and the goal is to fing anything findable from it\n",
    "* We want to do it efficiently: \n",
    "    * looking at either each piece of the graph only once for a small cost number of times.\n",
    "    * So looking for running time which is linear on the size of the graph that is big O(m+n).\n",
    "  \n",
    "**Generic algorithm**  \n",
    "(given grapg G, vertex s, no condition on edges m (there could be > or < than vertex))\n",
    "\n",
    "* look at either each piece of the graph only once =>\n",
    "    * we're gonna remember whether or not we explored it before. \n",
    "    * we need one Boolean per node \n",
    "    * (1) we will initialize it by having everything unexplored except S, our starting point we'll have it start off as explored\n",
    "* And it's useful to think of the nodes thus far as being in some sense territory conquered by the algorithm.\n",
    "    * there's going to be a frontier in between the conquered and unconquered territory. \n",
    "    * the goal of the generic outcome is that each step we supplement the conquered territory by one new node, assuming that there is one adjacent to the territory you've already conquered\n",
    "        * (2) while possible: \n",
    "            * choose and edge (Ð³Ð±Ð¼) with u explored and v unexplored\n",
    "            * if none, stop\n",
    "            * mark v explored\n",
    "\n",
    "**Claim:**  \n",
    "at the termination of this algorithm the node v â€“ explored <=> G has a path from s to v\n",
    "  \n",
    "* this claim and the proof holds whether or not G is an undirected graph or a directed graph. \n",
    "* almost all of the things in this course about graph search: breadth first search, depth first search also\n",
    "* the one big difference: connectivity computation\n",
    "\n",
    "Proof: \n",
    "* (=>) easy induciton on number of inerations\n",
    "* (<=) by contradiction:\n",
    "    * suppose G has a path p from s to v but v \n",
    "    * but v is unexplored at the end of the algorithm\n",
    "        * s for sure is explored since we initialize the algorithm this way\n",
    "        * we traverse this path from s to v: some points in the middle could be explored, some â€“ not\n",
    "        * in the middle of this path there is an edge by which we move from an explored vertex to an unexplored at some point: \n",
    "        * <=> (u,w) belonging to path where u - explored, w - unexplored\n",
    "        * u can be an s and w can be a v\n",
    "        * How is it possible that an algorithm terminated, but there is still this edge (u,v)\n",
    "        * generic search won't terminate without exploring w\n",
    "        * contradiction\n",
    "        * QED\n",
    "  \n",
    "**BFS vs DFS**\n",
    "* Note:\n",
    "    * there is a cut between explored and unexplored part woth crossing edges\n",
    "    * How to choose among frontier edges?\n",
    "* **Breadth-First-Search:**\n",
    "    * Explore nodes in layers: \n",
    "        * starting point S  = Layer-0. \n",
    "        * neighbors of S = Layer-1, \n",
    "        * Layer-2 will = nodes that are neighbors of Layer-1 but that are not already in layer 0 or 1\n",
    "        * So layer i+1, = nodes next to layer i that you haven't already seen yet. \n",
    "     * there's a close correspondence between these layers and **shortest path** distances.\n",
    "     * can also be used to compute **connected components** of an undirected graph in linear time O(n+m) if we use a correct data structure: a queue (FiFo)\n",
    "* **Depth-First-Search**\n",
    "    * A strategy of how you agressively explore a maze\n",
    "    * It's not, for example, very useful for computing shortest path information, but especially in directed graphs it's going to do some remarkable things for us. \n",
    "        * So, in directed acyclic graphs, so a directed graph with no directed cycles it will give us what's called the **topological ordering**. \n",
    "            * So it'll sequence the nodes in a linear ordering from the first to the last, so that all of the arcs of the directed graph go forward. \n",
    "            * So this is useful for example if you have a number of tasks that need to get completed with certain precedence constraints. \n",
    "        * Compute **connected components in directed graphs** (for undirected it doesn't mtter what to use) in O(n) time\n",
    "        \n",
    "**Time-wise**  \n",
    "* both of these are superb strategies for exploring a graph. \n",
    "* They're both linear time with very good constants. \n",
    "* DFS O(m+n) time in a graph with M edges and N vertices. \n",
    "* You do wanna use a different data structure reflecting the different search strategy. \n",
    "    * So, here because you're exploring aggressively, as soon as you get to a node you'll meet and you start exploring its neighbors, you wanna last-in first-out data structure, also known as a stack. \n",
    "    * Depth first search also admits a very elegant recursive formulation, and in that formulation, you don't even need to maintain a stack data structure explicitly, the stack is implicitly taken care of in the recursion.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 BFS basics \n",
    "\n",
    "* Linear time: O(m+n), no conditions on m and n\n",
    "* explaination on undirected, but this entire procedure will work in exactly the same way for a directed graph.\n",
    "\n",
    "**[Algorithm]**\n",
    "BFS(Graph G, start vertex s)\n",
    "* assume that all nodes are unexplored \n",
    "* mark s as explored\n",
    "* let Q = queue data structure (FiFo), initialized with s\n",
    "    * you can add stuff to the back in constant time \n",
    "    * and take stÐ³ff from the front in constant time\n",
    "    * FiFo = first in, first out\n",
    "* While Q â‰  nan:\n",
    "    * remove the first node of Q, call it v\n",
    "    * for each edge (v,w):\n",
    "        * if w unexplored: \n",
    "            * mark w as explored\n",
    "            * add w to Q at the end\n",
    "\n",
    "**[Steps]**  \n",
    "So now, when we follow the code, what happens? \n",
    "* G = {(s,a), (s,b), (a,c), (b,c), (b,d), (c,d), (c,e), (c,e)}\n",
    "* Well in the first iteration of the while loop we ask is the queue empty? \n",
    "    * No it's not, because S is in it. \n",
    "    * So we remove in this case the only node of the queue. \n",
    "    * It's S. \n",
    "* And then we iterate over the edges incident to S. \n",
    "    * Now there are two of them. \n",
    "        * between S and A \n",
    "        * between S and B. \n",
    "    * And again this is still a little under specified: the algorithm doesn't tell us which of those two edges we should look at. \n",
    "        * Turns out it doesn't matter. \n",
    "        * Each of those is a valid execution of breadth first search. \n",
    "        * But for concreteness, let's suppose that of the two possible edges, we look at the edge (s,a). \n",
    "    * So, then we ask, has A already been explored? \n",
    "        * No, it hasn't. \n",
    "    * We add A to the queue at the end and as explored. \n",
    "* Now we go back to the for loop, and so now we move on to the second edge. \n",
    "    * It's into S, that's the edge (s, b). \n",
    "    * So, we ask, have we already explored B? \n",
    "        * Nope, \n",
    "        * B gets marked as explored \n",
    "        * gets added to the queue at the end. \n",
    "* So the queue at this juncture has \n",
    "    * first a record for A, cause that was the first one we put in it after we took S out. \n",
    "    * And then B follows A in the queue. \n",
    "    * Again, depending on the execution this could go either way. But for concreteness, I've done it so that A got added before B. \n",
    "* So now we go back up to the while loop\n",
    "    * we say is the queue empty? \n",
    "        * Certainly not. \n",
    "        * There's actually two elements. \n",
    "    * Now we remove the first node from queue, \n",
    "        * in this case, that's the node A \n",
    "        * let's look at all the edges incident to A. \n",
    "        * And in this case A has two two incident edges. \n",
    "            * we look at (a,s) and ask an if statement: has S already been explored? Yes it has, no action needed\n",
    "            * (a,c) â€“Â C we haven't seen yet. \n",
    "            * C we can mark as explored and put in the queue. \n",
    "            * So, that's gonna be our number four. \n",
    "* So now how has the queue changed. \n",
    "    * we got rid of a. \n",
    "    * and so now B is in the front and we added c at the end. \n",
    "* We go back to the while loop, \n",
    "    * the queue is not empty, \n",
    "    * we take off the first vertex = b\n",
    "    * b has three incident edges, \n",
    "        * s â€“ irrelevant, \n",
    "        * c â€“ also irrelevant, \n",
    "        * (c, d)\n",
    "            * we can take the node d, mark it as explored and add it to the queue. \n",
    "            * So d is going to be the fifth one that we see. \n",
    "* And now the queue has the element C followed by D. \n",
    "* etc\n",
    "  \n",
    "The nodes are numbered according to the layer they are in\n",
    "  \n",
    "Breadth first search is a good way to explore a graph:\n",
    "* First, it finds everything findable, and obviously nothing else \n",
    "* and second, it does it without redundancy\n",
    "\n",
    "**Claim 1**  \n",
    "at the end of BFS, v explored <=> G has a path from sa to v (G - directed or undirected)  \n",
    "Reason: special case of generic algorithm\n",
    "* the forward direction of this claim is clear: \n",
    "    * if you actually find something (= if something's marked as explored) \n",
    "    * it's only because you found a sequence of edges that led you there. \n",
    "    * So the only way you mark something as explored is if there's a path from S to V. \n",
    "* Conversely, to prove that anything with an S to V, for with a path from V will be found, you can proceed by contradiction: \n",
    "    * you can look at the part of the path from S to V that, that BFS does successfully explore,\n",
    "    * and then you gotta ask, why didn't it go one more hop? \n",
    "    * It never would've terminated before reaching all the way to V. \n",
    "    \n",
    "\n",
    "**Claim 2**   \n",
    "* running time of main while loop = O(n_s + m_s), where \n",
    "    * n_s â€“ number of nodes reachable from s\n",
    "    * m_s â€“ number of edges reachable from s\n",
    "Reason: by inspection of code\n",
    "\n",
    "BFS(Graph G, start vertex s)\n",
    "* assume that all nodes are unexplored \n",
    "* mark s as explored **csnt**\n",
    "* let Q = queue data structure (FiFo), initialized with s **csnt**\n",
    "* While Q â‰  nan:\n",
    "    * remove the first node of Q, call it v **O(n_s)**\n",
    "    * for each edge (v,w): **O(m_s)**\n",
    "        * if w unexplored: **O(1)**\n",
    "            * mark w as explored\n",
    "            * add w to Q at the end\n",
    "            \n",
    "So we can summarize the total work done in this while loop as follows. \n",
    "* inicialization = O(1)\n",
    "* First we just think about the vertices\n",
    "    * so in this search we're only gonna ever deal, with the vertices that are findable from S.\n",
    "        * there are n_s of them. \n",
    "    * And what do we do for the given node? \n",
    "        * we insert it into the queue \n",
    "        * and we delete it from the queue. \n",
    "    * we're never gonna deal with a single node more than once. \n",
    "    * => constant time overhead per vertex that we ever see, \n",
    "    * => for all verticies O(n_s) \n",
    "* Now, a given edge, we might look at it twice. \n",
    "    * So, for an edge (v,w): once when we first look at the vertex v, and again when we look at the vertex w. \n",
    "    * Each time we look at an edge we do constant work. \n",
    "    * So that means we're only gonna do constant work per edge. \n",
    "    * O(2 m_s) = O(m_s)\n",
    "* So the overall running time is going to be proportional to \n",
    "    * the number of vertices findable from S \n",
    "    * plus the number of edges findable from S. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 BFS and Shortest paths\n",
    "\n",
    "Goal: Given BFS(Graph G, start vertex s), compute dist(v) = fewest number of edges on a path that leads to a particular node v?  \n",
    "(you can define this in the same way for undirected graphs or directed graphs)\n",
    "\n",
    "Extra code:\n",
    "* in the initialization step, you set your preliminary estimate of the distance, \n",
    "    * the number of the shortest path distance from S to vertex V \n",
    "        * if V equals S, you know you can get from S to S on a path of length zero, the empty path. \n",
    "        * And if it's any other vertex, you have no idea if there's a path to V at all. \n",
    "            * So let's just initially put plus infinity for all vertices other than the starting point. \n",
    "            * This is something we will of course revise once we actually discover a path to vertex V. \n",
    "\n",
    "    * initialize dist(v): \n",
    "        * 0 if v = s\n",
    "        * + infinity if v â‰  s\n",
    "\n",
    "* And the only other extra code you have to add is: \n",
    "    * when considering edge(v, w):\n",
    "        * if w unexplored, then set dist(w) = dist(v) + 1\n",
    "        \n",
    "        \n",
    "**[Algorithm]**\n",
    "ShortesPath(Graph G, start vertex s, finish vertex v)\n",
    "* assume that all nodes are unexplored\n",
    "* mark s as explored \n",
    "* let Q = queue data structure (FiFo), initialized with s csnt\n",
    "* initialize dist(v): \n",
    "    * 0 if v = s\n",
    "    * + infinity if v â‰  s\n",
    "* While Q â‰  nan:\n",
    "    * remove the first node of Q, call it v \n",
    "    * for each edge (v,w): \n",
    "        * if w unexplored: \n",
    "            * mark w as explored\n",
    "            * add w to Q at the end\n",
    "            * set dist(w) = dist(v) + 1\n",
    "\n",
    "**Claim**  \n",
    "at termination dist(v) = i <=> v is in the i-th layer  \n",
    "(i.e shortest s-v path has i edges)  \n",
    "Proof idea: \n",
    "* every layer-i node w is added to q by a layer-(i-1) node v via the edge (v,w)\n",
    "    *  So the inductive hypothesis tells that \n",
    "        * distances were correctly computed for everybody from the lower layers. \n",
    "        * So in particular, \n",
    "            * whoever this node V was from layer i minus one was responsible for discovering u, in layer i. \n",
    "            * it has a distance computed as i minus one. \n",
    "            * Yours is assigned to be one more than its, namely i. \n",
    "        * So that pushes through the inductive step everything in layer i indeed gets the correct label of a shortest path distance i away from S. \n",
    "        \n",
    "Shortest path calculation is an additional feature you get from this particular (BFG) algorithmÑŽ Others do not give it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 BFS and Undirected connectivity\n",
    "\n",
    "Let G = (V, E) an undirected graph  \n",
    "(And we're not going to assume that G is connected, because a part of a goal of this algorithm is to figure out if it is)\n",
    "  \n",
    "**Connected components of an undirected graph** = maximal regions that are connected (in which you can get from any vertex to any)\n",
    "\n",
    "**Formal definition:**  \n",
    "* equivalent classes of the relation u~v <=> there exist u-v path in G\n",
    "    * ~ is equivalence relation: \n",
    "        * reflexive: everything has to be related to itself: in a graph there is a path from any node to itself = the empty path.\n",
    "        * a couple of these relations have to be symmetric, meaning that if u and v are related then v and u are related. Because this is an undirected graph it's clear that this is symmetric.\n",
    "        * Finally equivalence classes have got to be transitive. So that means if u and v are related and so are v and w and so are u and w. \n",
    "        \n",
    "**Goal:** compute all connected components in O(n+m) time\n",
    "**Why?**\n",
    "* for physical networks: check if it is broken\n",
    "* graph vizualisation\n",
    "* clustering: quick and dirty heuristic, super fast: linear time\n",
    "    * set of web-pages, genomes, images\n",
    "    * and you have a pairwise funciton which tells you how much a pair of objects are alike [low score] / different [high score] \n",
    "    * Now here's a graph you can construct using these objects and the similarity data that you have about them. \n",
    "        * So you can have a graph where the nodes are the objects. \n",
    "        * for each object, you have a single node \n",
    "        * for a given pair of nodes, you put in an edge if and only if the two objects are very similar. \n",
    "        * So for example, you could put in an edge between two objects if and only if the score is at most ten.\n",
    "    * in this graph you've constructed, you can find the connected components. \n",
    "        * So each of these connected components will be a group of objects, which more or less are all very similar to each other\n",
    "        * So this would be a cluster of closely related objects in your database\n",
    "\n",
    "    \n",
    "**[Algorithm]**\n",
    "* all nodes unexplored [assume lablled 1 to n] **O(n)**\n",
    "* for i from 1 to n **O(n)**\n",
    "    * if i not yet explored **O(n)** (over all of the connetcted components)\n",
    "        * BFS(G,i) => finds all nodes and marks as explored in a connected component\n",
    "\n",
    "Note: finds every connected component.\n",
    "Running time: O(m+n) linear \n",
    "* Depending on the graph, m and n: one these might be bigger that the other. \n",
    "* So why is it O of m plus n? \n",
    "    * Well as far as the nodes, we have to do this initialization there where we mark them all as unexplored, so that takes constant time per node. \n",
    "    * We have just the basic overhead of a for loop, so that's constant time per node => O(n) for all nodes. \n",
    "    * And then recall we proved that within breadth first search, you do amount of work proportional. \n",
    "        * You do constant time for each node in that connected component. \n",
    "        * Now, each of the nodes of the graph is in exactly one of the connected components. \n",
    "        * So you'll do constant time for each node in the BFS in which you discover that node. \n",
    "        * So that's again, O(n) over all of the connected components.\n",
    "    * And as far as the edges, note we don't even bother to look at edges until we're inside one of these BFS calls. \n",
    "        * They played no role in the outer for loop or in the pre-processing. \n",
    "        * And remember what we proved about an indication of breadth first search. \n",
    "        * The running time, you only do constant amount of work per edge in the connected component that you're exploring. \n",
    "        * In the worst case, you look at an edge once from either endpoint and each of that triggers a constant amount of work\n",
    "        * So when you discover a given connected component, the edge work is proportional to the number of edges in that kind of component. \n",
    "        * Each edge of the graph is only in exactly one of the connect components, so over this entire for loop, over all of these BFS calls. \n",
    "        * For each edge of the graph, you'll only be responsible for a constant amount of work of the algorithm. \n",
    "    * So summarizing because breadth-first search from a given starting node works in time\n",
    "        * O(m+n) \n",
    "            * m: O(1) per edge in each BFS\n",
    "            * n: O(1) per node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 DFS basics\n",
    "\n",
    "* explore aggressively, only backtrack when necessary\n",
    "    * we have to go next to one to immediate neighbours\n",
    "    * when we meet an explored node, we retreat back to nodes and check whether there are edges we haven't follow to explore neighboring nodes\n",
    "\n",
    "* Why bother with another strategy?\n",
    "    * also computes a topological ordering of a directed acyclic graph\n",
    "    * and strongly connected components of directed graphs\n",
    "\n",
    "* Linear time O(m+n)\n",
    "\n",
    "**[Algorithm 1]**  \n",
    "Minor modifications in BFS\n",
    "* Difference: \n",
    "    * istead of queue â€“Â a stack: LiFo\n",
    "        * supports constant time insertions to the front and constant time deletions from the front\n",
    "\n",
    "DFS(Graph G, start vertex s)\n",
    "* assume that all nodes are unexplored\n",
    "* mark s as explored\n",
    "* let S = stack data structure (LiFo), initialized with s\n",
    "* While Q â‰  nan:\n",
    "    * remove the first node of S, call it v\n",
    "    * chose an edge (v,w):\n",
    "        * if w unexplored:\n",
    "            * mark w as explored\n",
    "            * add w to S to the Front\n",
    "\n",
    "\n",
    "**[Algorithm 2]**  \n",
    "Recursive version\n",
    "\n",
    "DFS(Graph G, start vertex s)\n",
    "* mark s as explored\n",
    "* for every edge (s,v):\n",
    "    * if v unexplored\n",
    "        * mark v as explored\n",
    "        * DFS(G,v)\n",
    "\n",
    "**Claim 1**  \n",
    "at the end of DFS, v explored <=> G has a path from s to v (G - directed or undirected)\n",
    "Reason: special case of generic algorithm\n",
    "\n",
    "**Claim 2**  \n",
    "running time is O(n_s + m_s) (G - directed or undirected)\n",
    "* n_s â€“ number of nodes reachable from s \n",
    "* m_s â€“ number of edges reachable from s \n",
    "\n",
    "Reason: look at each node in connected components of s at most once, each edge at most twice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 Topological sort\n",
    "\n",
    "**Definition**  \n",
    "* topological ordering of a **directed graph** is an ordering of the vertices of a graph so that \n",
    "    * all of the arcs only go forward in the ordering. \n",
    "\n",
    "Mathematical def:  \n",
    "topological ordering of a directed graph is a labelling F from 1 to n of verticies of G such that:\n",
    "* (1) the F(v)'s are the set {1, 2, ..., n}\n",
    "* (2) (u,v) belong to G => f(u)<f(v)\n",
    "\n",
    "**Motivation**  \n",
    "Ordering of tasks while respecting all precedence constraints\n",
    "\n",
    "**Note**  \n",
    "* If a directed graph has a directed cycle â€“Â no topological ordering\n",
    "* What if you don't have a cycle?\n",
    "\n",
    "**Theorem**\n",
    "no directed cycle => can compute topological ordering\n",
    "\n",
    "**Solution 1 Algorithm**\n",
    "* Observation: Every directed acyclic graph has a sink vertex. That is a vertex without any outgoing arcs.\n",
    "    * Suppose there is not (ie every vertex has an outgoing edge)\n",
    "    * We can start in an arbitrary node. \n",
    "    * We know it's not a sink vertex, because we're assuming there aren't any. \n",
    "    * So there's an outgoing arc, we follow it.\n",
    "    * We get to some other node.\n",
    "    * We just keep following outgoing arcs, and we do this as long as we want because every vertex has at least one outgoing arc. \n",
    "    * There's a finite number of vertices, right this graph has say N vertices. \n",
    "        * So if we follow N arcs, we are going to see N+1 vertices. \n",
    "        * So by the pigeon-hole principle, we're going to see some vertex twice. \n",
    "        * we have exhibited a directed cycle. \n",
    "    * we just prove that a graph with no sink vertex has to have a directed cycle. \n",
    "    * So a directed acyclic graph therefore has to have at least one sink vertex\n",
    "    * QED\n",
    "* Suppose the acyclic graph did have a topological ordering\n",
    "    * The vertex which goes last in it\n",
    "    * Every arc that goes back in ordering is a violation\n",
    "    * Last vertex should not have an outgoing arc = should be sink vertex\n",
    "    * All nodes with outgoing arcs we put earlier\n",
    "    * As far as graph is directed acyclic, we know there is a sink vertex (at least one)\n",
    "\n",
    "* (1) let v to be a sink vertex of G (if there are many, we pick one arbitrary)\n",
    "* (2) we put it into the n-th position of F: F(v) = n\n",
    "* (3) we recurse on the rest of the graph G-{v} \n",
    "\n",
    "Why does this algorithm work?\n",
    "* (1) we need to argue that in every iteration we can indeed find the sink vertex, \n",
    "     * if you take a directed acyclic graph and you delete one or more vertices from it, you're still going to have a directed acyclic graph\n",
    "     * You can't create cycles by just getting rid of stuff. \n",
    "     * You can only destroy cycles, and we started with no cycles. \n",
    "     * So through all the intermediate recursive calls we have no cycles by our first observation is always the sink.\n",
    "* (2) So the second that that we have to argue is that we really do produce a topological ordering. \n",
    "    * That means for every edge of the graph, it goes forward in the ordering. \n",
    "    * That is the head of the arc is given a position later than the tail of the arc.\n",
    "    * And this simply follows because we always use sink vertices. \n",
    "         * So consider the vertex v which is assigned to the position i. \n",
    "         * This means then, that when we're down to a graph that only has i vertices remaining, v is the sink vertex.\n",
    "         * If v is the sink vertex when only the first i vertices remain, what property does it have in the original graph? \n",
    "         * Well, it means all of outgoing arcs that it has have to go to vertices that were already deleted and assigned higher positions. \n",
    "         * So for every vertex, by the time it actually gets assigned a position, it's a sink and it only has incoming arcs from the as yet unsigned vertices. \n",
    "         * It's outgoing arcs all go forward to vertices that were already assigned higher positions, and got deleted previously from the graph.\n",
    "\n",
    "This guarantees that as long as you don't have a cycle, the topological ordering does indeed exist. Proof by construction of algorithm above.\n",
    "* Good algorithm, O(n+m) time\n",
    "\n",
    "**Solution 2 DFS-based algorithm**\n",
    "\n",
    "DFS(graph G, start vertex s) = inner loop\n",
    "* mark s as explored\n",
    "* for every edge (s,v):\n",
    "   * if v unexplored\n",
    "      * DFS(G,v)\n",
    "* set F(s) = current label\n",
    "* current label -= 1\n",
    "\n",
    "DFS-Loop(graph G, start vertex s) = outer loop\n",
    "* Mark all nodes unexplored\n",
    "* Current_label = n (global variabel to keep track of ordering)\n",
    "* for each vertex v belonging to G\n",
    "    * if v not yet explored (in some previous DFS call)\n",
    "        * DFS(G, v)\n",
    "\n",
    "\n",
    "* Let directed graph G {(s,v), (v,t), (s,w), (w,t)}\n",
    "* In the outer loop we take an arbitrary vertex b\n",
    "    * we call DFS(G, v): \n",
    "        * mark v = explored\n",
    "        * the only vertex we can explore is dt: so for edge (b,t)\n",
    "            * mark t as explored\n",
    "            * DFS(G,t), but from t there is no way to go, recursion stops\n",
    "        * so we assign F(t) = current label = 4\n",
    "        * current label becomes 3\n",
    "    * we backtrack to v\n",
    "        * there is nothing to explore\n",
    "        * we set F(v) = 3\n",
    "        * we decrement current label = 2\n",
    "* We get out of this loop and consider the next vertex, let it be s\n",
    "    * we haven't seen it yet\n",
    "    * there are 2 arcs to explore\n",
    "        * (s,v) we saw v, so we skip it\n",
    "        * (s,w) => DFS(G,w)\n",
    "            * we explore t, but it is already seen\n",
    "            * we finish the DFS with w and set F(w) = 2\n",
    "            * we decrement current label = 1\n",
    "    * we backtrack to s\n",
    "        * we've already considered all its arks and it gets the current label F(s) = 1\n",
    "        \n",
    "**Running time:** O(m + n)  \n",
    "**Reason:** O(1) time per node, O(1) time per edge  \n",
    "**Correctness:** need to show that if (u,v) is an edge, then f(u) < f(v)\n",
    "\n",
    "Proof: \n",
    "* The proof of correctness splits into two cases, depending on which of the vertices u or v is visited first by depth-first search. \n",
    "* Because of our for loop, which iterates over all of the vertices of the graph g, depth-first search is going to be invoked exactly once from each of the vertices. \n",
    "* Either u or v could be first, both are possible. \n",
    "\n",
    "Case 1:\n",
    "* So first let's assume that u was visited by DFS before v, \n",
    "* DFS on a node, is going to find everything findable from that node. \n",
    "     * So if u is visited before v, that means v isn't getting explored, so it's a candidate for being discovered. \n",
    "     * Moreover, there's a an arc straight from u to v, so certainly DFS invoked at u is going to discover v. \n",
    "     * Furthermore, the recursive call corresponding to the node v is going to finish, it's going to get popped off the program stack before that of u. \n",
    "     * The easiest way to see this is just to think about the recursive structure of depth-first search. \n",
    "         * So when you call depth-first search from u, that recursive call, that's going to make further recursive calls to all of the relevant neighbors including v, and u's call is not going to get popped off the stack until v's does beforehand. \n",
    "         * That's because of the last in, first out nature of a stack or of a recursive algorithm.\n",
    "         * So because v's recursive call finishes before that of u, that means it will be assigned a larger label than u. \n",
    "         * Because the labels keep decreasing as more and more recursive calls get popped off the stack. \n",
    "  \n",
    "Case 2:  \n",
    "* v is visited before u. \n",
    "* And here's where we use the fact that the graph has no cycles. \n",
    "    * So there's a direct arc from u to v. \n",
    "    * That means there cannot be any directed path from v all the way back to u. \n",
    "    * That would create a directed cycle.\n",
    "    *  Therefore, DFS invoked from v is not going to discover u. \n",
    "    * There's no directed path from v to u\n",
    "* So it doesn't find u at all. \n",
    "    * So the recursive call of v again is going to get popped before u's is even pushed onto the stack. \n",
    "    * So we're totally done with v before we even start to consider u. \n",
    "    * So therefore, for the same reasons, since v's recursive call finishes first, its label is going to be larger, which is exactly what we wanted to prove. \n",
    "    \n",
    "QED    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6 Computing strong components (based on DFS)\n",
    "\n",
    "**[Kosaraju 2-pass Algorithm]**  \n",
    "\n",
    "What are connected components of **directed graphs**?\n",
    "the **strongly connected components** (SCCs) of a directed graph G are the equivalence classes of the relation\n",
    "u~v <=> there is a path from u to v **and** from v to u in G\n",
    "\n",
    "You check: ~ is an equivalence relation\n",
    "\n",
    "The algorithm to compute SCCs is build on DFS, but\n",
    "* If you call DFS from just the right place, you'll actually uncover an SCC. \n",
    "* If you call it from the wrong place, it will give you no information at all.\n",
    "\n",
    "**Theorem** SCC's of directed graph can ne computed in linear time O(m+n)\n",
    "\n",
    "* (1) Let G_rev = G with all arcs reversed\n",
    "    * Construction of this G_rev can be done in 2 ways:\n",
    "        * the naive way to implement this would be to literally construct a new copy of the input graph with all the the arcs in the reverse direction, and then just run depth first search on it. \n",
    "        * the sort of optimization would be to just run DFS on the original graph, but going across arcs backwards. \n",
    "* (2) run DFS-Loop on G_rev\n",
    "    * that just means the user will check more to make sure that you see all of the nodes of the graph \n",
    "        * even if it's disconnected you have an outer loop where you just try each starting point separately. \n",
    "        * If you haven't already seen it then you run DFS from that given node. \n",
    "    * goal: discovers the \"required magical\" order of nodes in which running the second DFS-loop will disover SCCs\n",
    "    * let f(v) = finishing time of each v belonging to G\n",
    "* (3) run DFS-Loop on G\n",
    "    * goal: discovers the SCCs one by one\n",
    "    * processing nodes in decreasing order of finishing times\n",
    "    * we're going to label each node in the second pass with what we call a leader. \n",
    "        * And the idea is that the nodes in the same strong connected component will be labeled with exactly the same leader node. \n",
    "\n",
    "**DFS-Loop**\n",
    "DFS-Loop(Graph G)\n",
    "* global variable t = 0 \n",
    "    * = number of nodes processed so far\n",
    "    * used to compute finishing times in first pass\n",
    "* global variable s = NULL\n",
    "    * = current vertex from which DFS was initiated\n",
    "    * used to compute leaders\n",
    "* Assume nodes labeled 1 to n\n",
    "* For i from n down to 1\n",
    "    * \"\"\"s is responsible for keeping track of the most recent node from which Depth First Search had been initiated, \n",
    "    * \"\"\" so if i's not explored and we initiate a Depth First Search from it, we better reset s\n",
    "    * if i not yet explored \n",
    "        * s == i\n",
    "        * DFS(G, i)            \n",
    "        \n",
    "DFS(graph G, node i) = inner loop\n",
    "* mark i as explored \n",
    "    * \"\"\" once a node is marked explored, it's explored for this entire indication of DFS-Loop.\n",
    "    * \"\"\" so even if this DFS from a given node i finishes, and then the outer for loop marches on, and encounters i again, it's still going to be marked as explored.\n",
    "* set leader(i) = node s\n",
    "* for every edge (i,j) belonging to j:\n",
    "    * if j unexplored\n",
    "      * DFS(G,v)\n",
    "* t += 1\n",
    "* set F(i) == t (finishing time)\n",
    "   \n",
    "   \n",
    "Example on a particular graph\n",
    "* First pass on reveresed graph gives the \"magical order\" of nodes = f(i)'s\n",
    "* Second run on direct graph: \n",
    "    * you reverse arcs\n",
    "    * you replace node numbers by newly found f(i)'s\n",
    "  \n",
    "Running time: 2 DFS = O(m+n)\n",
    "\n",
    "**[Analysis]**\n",
    "* observation: every directed graph has two levels of granularity. \n",
    "    * zoom out: you see is a directed acyclic graph, of course comprising its strongly connective components. \n",
    "    * zoom in: and focus on the fine grain structure with one SCC. \n",
    "    \n",
    "<=> **Claim:** SCC of a directed graph induce in a natural way an **acyclic metagraph**\n",
    "* meta-nodes = the SCCs C1, ..., Ck of G\n",
    "* There is an arc C -> C^ <=> There is arc (i,j) belonging to G with i belonging to C and j belonging to C^\n",
    "\n",
    "Why this metagraph is acyclic?\n",
    "* Metanodes = SSC's (= ie you can get from anywhere to anywhere else within it)\n",
    "* So, if you had a cycle that involved two different metanodes, \n",
    "    * on such a directed cycle you can also get from anywhere to anywhere else. \n",
    "    * So if you had two supposedly distinct SCCs, that you could get from the one to the other and vice versa, they would collapse into a single SCC. \n",
    "        * You can get from anywhere to anywhere in one, anywhere from anywhere in the other one, and you can also go between them at will, so you can get from anywhere in this union to anywhere in the union. \n",
    "        \n",
    "The SCCs of G are exactly the same as SCCs of G_rev\n",
    "\n",
    "**Key Lemma**  \n",
    "* Consider 2 adjecent SCCs in G: C1 and C2 (C2 is \"downstream\" to C1)\n",
    "* Let f(v) = finishing times of DFS-loop in G_rev\n",
    "* Then: max(f(v in C1)) < max(f(v in C2) \n",
    "\n",
    "assume that this lemma is true. Then:\n",
    "* Corollary: \n",
    "    * max time of the entire graph (where the second pass of DFS would begin)\n",
    "    * it has to be in a \"sink SCC\" (by transitivity, applying lemma to metanode pairs) \n",
    "        * By contradiction\n",
    "        * Consider this SCC with the maximum F value. \n",
    "        * Suppose it was not a sink SCC that it has an outgoing arch\n",
    "        * follow that outgoing arch to get some other SCC \n",
    "        * by the lema the SCC you've got into has even bigger maximum finishing time. \n",
    "        * So that contradicts the fact that you started in the SCC with a maximum finishing time. \n",
    "    \n",
    "**Correctness intuition of the Agorithm**  \n",
    "(see notes for formal proof)\n",
    "* Assuming the lemma is true we know that the corollary is true. \n",
    "* Now using this corollary let's finish the proof of correctness, of Kasaraja's algorithm, \n",
    "* We can locate max finishing time somewhere in some sink SCC. \n",
    "  \n",
    "By corollary: \n",
    "* 2nd pass of DFS-Loop begins somwhere un a sink SCC C*\n",
    "    * because otherwise DFS would discover everything downstream (ie all other metanodes)\n",
    "* => first call of DFS discovers C* and nothing else\n",
    "* => rest of DFS-Loop would be recursing on G-{C*}\n",
    "* We start at a sink metanode that has largest max finishing time\n",
    "* and so on: Successive calls to DFS(G,i) peel of the SCCs one by one in reverse topological order of the metagraph)\n",
    "   \n",
    "**Proof of Lemma**\n",
    "* Let's reverse the graph G to G_rev\n",
    "    * C1 and C2 (C1 is \"downstream\" to C2)\n",
    "    * arc points from j (belonging to C2) to i (belonging to C1)\n",
    "    * The SCCs in rev graph are exactly the same as in straight graph\n",
    "* now we're going to have two cases in this proof \n",
    "* Let v = 1st node of (C1 and C2) reached by DFS-Loop (on G_rev)\n",
    "* Case 1: we encounter v in C1\n",
    "    * all of C1 explored before C2 ever reached\n",
    "    * reason: no paths from C1 to C2 sicne metagraph is acyclic\n",
    "    * => every single finishing time in C1 is smaller, than in every single finishing time in C2\n",
    "* Case 2: we encounter v in C2\n",
    "    * here we use the fact that we are using DFS, not another algorithm\n",
    "    * DFS(G_rev, v) won't finish untill all of C1 and C2 completely explored. \n",
    "    * => And we won't finish with V until we finish with everything else, that's the depth-first search property. \n",
    "    * For that reason the finishing time of this vertex V will be the largest of anything reachable from it. \n",
    "    * So in particular it'll be larger than everything in C2 \n",
    "    * but more to the point, it'll be larger than everything in C1 which is what we are trying to prove.\n",
    "    * f(v) > f(w) for all w in C1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.7 Web Structure\n",
    "\n",
    "* vericies = web pages\n",
    "* edges are directed: links\n",
    "\n",
    "Q: what does the web graph look like?\n",
    "[assume you've already crawled the all information from the web]\n",
    "Size: 200 million nodes, 1 billion edges (year 2000)\n",
    "* => it's impossible to compute the whole graph\n",
    "* => Compte the SCCs of the web\n",
    "\n",
    "Today you have\n",
    "* Map reduce and Hadoop \n",
    "    * specialized systems which are meant to operate on massive data sets. \n",
    "    * And in particular, they can do things like compute connectivity information on graph data\n",
    "* But the web is much larger\n",
    "\n",
    "**The Bow Tie picture of the web**\n",
    "\n",
    "* In the middle â€“Â giant SCC (core of the web) \n",
    "    * It would be super weird if there were two different blobs, 10 million web pages each that somehow were not mutually reachable from each other\n",
    "* Out region = reachable form giant, but you'd not go back\n",
    "    * corporate sites\n",
    "* In region = \n",
    "    * new web pages\n",
    "* There are hyperlinks which go from the in to out without traversing giant = tubes\n",
    "* There parts connected to In part which store \"heads\" of hyperlinks from In = tendrils\n",
    "* There parts connected to Out part which store \"tails\" of hyperlinks firected to Out\n",
    "* Isolated islands\n",
    "\n",
    "\n",
    "**Main findings**\n",
    "* all 4 parts: giant, in, out, residual parts are roughtly of the same size 25%\n",
    "    * giant might be a little bit bigger\n",
    "* within core, very well connected \n",
    "    * has the \"small world\" property [Milgram]\n",
    "    * = six degrees of separation\n",
    "    * => routing information is easy (in small world networks)\n",
    "* outside very poor connectivity\n",
    "\n",
    "**Modern Web Research**\n",
    "1. temporal aspects â€“Â evolution of the graph\n",
    "2. informational aspects â€“Â how does new information propagate through the web (socail networks)\n",
    "3. finer-grained structure â€“Â how to define and compute communities in information and social networks (cuts as baby step)\n",
    "\n",
    "Reading: Easley + Kleinberg \"Networks, Crowds, Markets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem set 5 (Main)\n",
    "\n",
    "**1. Given an adjacency-list representation of a directed graph, where each vertex maintains an array of its outgoing edges (but *not* its incoming edges), how long does it take, in the worst case, to compute the in-degree of a given vertex? As usual, we use n and m to denote the number of vertices and edges, respectively, of the given graph. Also, let k denote the maximum in-degree of a vertex. (Recall that the in-degree of a vertex is the number of edges that enter it.)**\n",
    "\n",
    "* G(V,E) = {m, n}\n",
    "* v belonging to V\n",
    "* k = max in-degree \n",
    "* Adj = adjacency list of edges for each vertex pf G\n",
    "\n",
    "* We must read all edges (or the edge not read may contribute to a in-degree count of the given vertex), so we have the time lowered bounded by m\n",
    "* We can compute the in-degree by just reading all edges and keep track of the in-degree count, so we have the time upper bounded by m\n",
    "\n",
    "> answer is Theta(m)\n",
    "\n",
    "* The out-degree ov vertex v = length of Adj[v]\n",
    "    * The time to compute the out-degree of v is Theta(length of Adj[v]) \n",
    "* The sum of lengths of Adj lists for all verticies = n\n",
    "    * The time to compute the out-degree of all verticies is Theta(m+n)\n",
    "* The in-degree ov vertex v = number of times it appears in all the Adj lists \n",
    "    * If we search all the lists for each vertex, the time to compute the in-degree of all vertices is Theta(m * n)\n",
    "    * Alternatively, we can allocate a counter k initialize it to zero. \n",
    "        * Then we only need to scan the lists in Adj once, \n",
    "        * incrementing k when we see v in the lists. \n",
    "        * so we only scan all lists which are edges => time is Theta(m)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Consider the following problem: given an undirected graph G with n vertices and m edges, and two vertices s and t, does there exist at least one s-t path?**  \n",
    "\n",
    "**If G is given in its adjacency list representation, then the above problem can be solved in O(m+n) time, using BFS or DFS. (Make sure you see why this is true.)**  \n",
    "\n",
    "**Suppose instead that G is given in its adjacency *matrix* representation. What running time is required, in the worst case, to solve the computational problem stated above? (Assume that G has no parallel edges.)**\n",
    "\n",
    "* Naive Algorithm:\n",
    "    * we mark all points as undiscovered\n",
    "    * we take point s, mark it as discovered\n",
    "    * (Rec) we scan all other points of the graph of a fact to be linked to s = n-1 scans\n",
    "        * if there is t, we stop\n",
    "        * we mark all points that are linked a as discovered\n",
    "        * if not for each discovered point  \n",
    "             * (Rec) (= we scan through verticies which are not discovered)\n",
    "\n",
    "* Lower bound: every time we want to find the edges adjacent to a given vertex ð‘¢, we have to traverse the whole array, which is of length ð‘›; this happens for all the vertices\n",
    "    * Worst case example: linear graph from s to t: on each step you scan n-1, n-2, etc => n(n-1)/2 => O(n^2)\n",
    "* Upper bound: \n",
    "    * first build an adjacency list representation in Theta(ð‘›2) time, \n",
    "    * with a single scan over the given adjacency matrix and then run BFS or DFS as in the video lectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. This problem explores the relationship between two definitions about graph distances. In this problem, we consider only graphs that are undirected and connected. The diameter of a graph is the maximum, over all choices of vertices s and t, of the shortest-path distance between s and t. (Recall the shortest-path distance between s and t is the fewest number of edges in an s-t path.)**\n",
    "\n",
    "**Next, for a vertex s, let l(s) denote the maximum, over all vertices t, of the shortest-path distance between s and t. The radius of a graph is the minimum of l(s) over all choices of the vertex s.**\n",
    "\n",
    "**Which of the following inequalities always hold (i.e., in every undirected connected graph) for the radius rr and the diameter d? [Select all that apply.]**\n",
    "\n",
    "**(a) r â‰¤ d/2\n",
    "**(b) r â‰¥ d/2\n",
    "**(c) r â‰¥ d\n",
    "**(d) r â‰¤ d**\n",
    "\n",
    "* l(s_i) is the maximum shortest path involving s_i as starting point\n",
    "* d = diameter = is maximum among l(s_i)\n",
    "* r = radius = minimum among l(s_i)\n",
    "* the answer (d) is correct\n",
    "\n",
    "* Let's take vertex c which represents the radius of G\n",
    "    * => it is involved in the *shortest* maximal [minimal path]\n",
    "    * => the distance from c to all other points is at most r\n",
    "    * => the distance to s which is involved in diameter is =< r\n",
    "    * => the distance to t which is involved in diameter is =< r\n",
    "* if c is on the d-path from s to t\n",
    "    * (s,c) =< r and (c,t) =< r\n",
    "    * => d =< 2r \n",
    "* else [c is away from the d-path from s to t]\n",
    "    * any other path from s to t is bigger than d\n",
    "    * the path through c is bigger than d\n",
    "    * the path through c is smaller than 2r \n",
    "    * => d =< 2r\n",
    "* => d/2 =< r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Consider our algorithm for computing a topological ordering that is based on depth-first search (i.e., NOT the \"straightforward solution\"). Suppose we run this algorithm on a graph G that is NOT directed acyclic. Obviously it won't compute a topological order (since none exist). Does it compute an ordering that minimizes the number of edges that go backward?**\n",
    "\n",
    "**For example, consider the four-node graph with the six directed edges (s,v),(s,w),(v,w),(v,t),(w,t),(t,s). Suppose the vertices are ordered s,v,w,t. Then there is one backwards arc, the (t,s) arc. No ordering of the vertices has zero backwards arcs, and some have more than one.**\n",
    "\n",
    "* since we can start Topological DFS-Loop from any vertex, we can do that from vertex v from the example\n",
    "  \n",
    "* we mark all nodes unexplored\n",
    "* set current label at 4\n",
    "* Outer loop: for vertex v\n",
    "    * v unexplored \n",
    "        * => DFS call(G,v): mark v as explored\n",
    "        * DFS(v,t): mark t explored\n",
    "        * DFS(t,s): mark s explored\n",
    "        * DFS(s,v): v explored, backtrack to s\n",
    "        * DFS(s,w): mark w explored\n",
    "        * DFS(w,t): t explored, backtrack to w\n",
    "            * there is no more way to go from w => F(w) = 4\n",
    "            * backtrack to s, there is no more way to go from s => F(s) = 3\n",
    "            * backtrack to t, there is no more way to go from t => F(t) = 2\n",
    "            * backtrack to v: DFS(v,w)\n",
    "                * w explored, backtrack to v, there is no more way to go from v => F(s) = 1\n",
    "* Thus the \"order\" would be following: v, t, s, w\n",
    "    * and there would be 2 backward arcs: (s,v), (w,t)\n",
    "* and if we run the algorithm from vertex s, there would be only one arc\n",
    "    * => correct answer is \"sometimes yes, sometimes no\"\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. On adding one extra edge to a directed graph G, the number of strongly connected components...?**\n",
    "\n",
    "* if we take a graph where each node is a strongly connected component\n",
    "    * vertices: a,b,c,d,e\n",
    "    * edges: (a,b), (b,c), (b,e), (b,d), (d,e), (c,e)\n",
    "* if we add an edge (a,c) â€“Â nothing changes\n",
    "* if we add an edge (c,a) â€“Â (a,c,e) merge into a single SCC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Problems 5\n",
    "\n",
    "**In the 2SAT problem, you are given a set of clauses, where each clause is the disjunction of two literals (a literal is a Boolean variable or the negation of a Boolean variable). You are looking for a way to assign a value \"true\" or \"false\" to each of the variables so that all clauses are satisfied --- that is, there is at least one true literal in each clause. For this problem, design an algorithm that determines whether or not a given 2SAT instance has a satisfying assignment. (Your algorithm does not need to exhibit a satisfying assignment, just decide whether or not one exists.) Your algorithm should run in O(m+n) time, where mm and nn are the number of clauses and variables, respectively. [Hint: strongly connected components.]**\n",
    "\n",
    "* Things to know\n",
    "    * SAT (Boolean satisfiability problem) is the problem of assigning Boolean values to variables to satisfy a given Boolean formula. \n",
    "    * The Boolean formula will usually be given in CNF (conjunctive normal form), which is \n",
    "        * a conjunction of multiple clauses, \n",
    "        * where each clause is a disjunction of literals (variables or negation of variables). \n",
    "    * 2-SAT (2-satisfiability) is a restriction of the SAT problem, in 2-SAT every clause has exactly two literals.\n",
    "        * (a V !b) ^ (!a V b) ^ (!a V !b) ^ (a V c)\n",
    "    * Note: \n",
    "        * (a V b) is equivalent to (!a => b) ^ ( !b => a) (if one variable is false, other must be true) \n",
    "        * that's called implicative normal form \n",
    "    * we can construct a directed graph from the initial expression \n",
    "        * transform each clause into implicative normal form\n",
    "        * verticies: a, !a, b, !b, etc\n",
    "        * edges: implications\n",
    "    * Note:\n",
    "        * if x is reachable from !x and !x is reachable from x the problem has no solution\n",
    "        * because if x=true => !x=true, which is false\n",
    "* If 2 vertex are mutually reachable, they are in a single SCC\n",
    "    * => In order for 2-SAT problem to have a solution, it is necessary and sufficient that for any variable x the vertices x and !x are in different strongly connected components of the strong connection of the implication graph.\n",
    "    \n",
    "    \n",
    "Algorithm:\n",
    "1. First pass of Kosaraju algorithm gives us \n",
    "\n",
    "https://cp-algorithms.com/graph/2SAT.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Assignment 5\n",
    "\n",
    "**The file contains the edges of a directed graph. Vertices are labeled as positive integers from 1 to 875714. Every row indicates an edge, the vertex label in first column is the tail and the vertex label in second column is the head (recall the graph is directed, and the edges are directed from the first column vertex to the second column vertex).** \n",
    "\n",
    "**So for example, the 11-th row looks like : \"2 47646\". This just means that the vertex with label 2 has an outgoing edge to the vertex with label 47646**\n",
    "\n",
    "**Your task is to code up the algorithm from the video lectures for computing strongly connected components (SCCs), and to run this algorithm on the given graph.**\n",
    "\n",
    "**Output Format: You should output the sizes of the 5 largest SCCs in the given graph, in decreasing order of sizes, separated by commas (avoid any spaces). So if your algorithm computes the sizes of the five largest SCCs to be 500, 400, 300, 200 and 100, then your answer should be \"500,400,300,200,100\" (without the quotes). If your algorithm finds less than 5 SCCs, then write 0 for the remaining terms. Thus, if your algorithm computes only 3 SCCs whose sizes are 400, 300, and 100, then your answer should be \"400,300,100,0,0\" (without the quotes). (Note also that your answer should not have any spaces in it.)**\n",
    "\n",
    "**WARNING: This is the most challenging programming assignment of the course. Because of the size of the graph you may have to manage memory carefully. The best way to do this depends on your programming language and environment, and we strongly suggest that you exchange tips for doing this on the discussion forums.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative approach to PA5 (works on full dataset)\n",
    "\n",
    "**Data Structures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node labels range from 1 to 875714\n",
    "num_nodes = 875714\n",
    "\n",
    "# Adjacency representations of the graph and reverse graph\n",
    "gr = [[] for i in range(num_nodes)]\n",
    "r_gr = [[] for i in range(num_nodes)]\n",
    "\n",
    "# The list index represents the node. If node i is unvisited then visited[i-1] == False and vice versa\n",
    "visited = [False] * (num_nodes)\n",
    "\n",
    "\n",
    "# Stack for DFS\n",
    "stack = deque()\n",
    "\n",
    "# The finishing times arranged by node index after the first pass\n",
    "fin_times = [0 for i in range(num_nodes)]\n",
    "\n",
    "# The order of nodes arranged by finishing times (after the first pass)\n",
    "fin_times_node_order = [0 for i in range(num_nodes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data into direct and reverse graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final data\n",
    "file = open(\"../algorithms_course_code/data/pg_asmt_5_scc.txt\", 'r')\n",
    "data = file.readlines()    \n",
    "for line in data:\n",
    "    items = line.split()\n",
    "    gr[int(items[0])-1] += [int(items[1])]\n",
    "    r_gr[int(items[1])-1] += [int(items[0])]\n",
    "file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "# [!] before loading change number of nodes in \"data structures\" clause\n",
    "\n",
    "def loadGraphTest():\n",
    "    file = open(\"../algorithms_course_code/data/pg_asmt_5_scc_test_cases.txt\", 'r')\n",
    "    graph = []\n",
    "    for line in file:\n",
    "        line_strip = line.rstrip(\"\\n\")\n",
    "        line_split = line_strip.split(\" \")\n",
    "        if line_split != ['']:\n",
    "            line_split_int = [int(i) for i in line_split]\n",
    "            graph.append(line_split_int)\n",
    "    file.close()    \n",
    "    return graph\n",
    "\n",
    "test1 = loadGraphTest()\n",
    "# test data copy to prevent modification of uploaded\n",
    "test2 = [edge[:] for edge in test1]\n",
    "\n",
    "for edge in test2:\n",
    "    gr[int(edge[0])-1] += [int(edge[1])]\n",
    "    r_gr[int(edge[1])-1] += [int(edge[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DFS on reverse graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final on lists (without print)\n",
    "def dfsReverseFinTimes(r_gr):\n",
    "    time = 1    \n",
    "    global stack\n",
    "    global visited\n",
    "    global fin_times\n",
    "    \n",
    "    for node in range(num_nodes, 0, -1):\n",
    "        stack.append(node)\n",
    "        \n",
    "        while len(stack) > 0:\n",
    "            stack_node = stack.pop()\n",
    "                \n",
    "            if visited[stack_node-1] == False:\n",
    "                visited[stack_node-1] = True\n",
    "                stack.append(stack_node)\n",
    "                \n",
    "                for out_node in r_gr[stack_node-1]:\n",
    "                    if visited[out_node-1] == False:\n",
    "                        stack.append(out_node)              \n",
    "            else:\n",
    "                if fin_times[stack_node-1] == 0:\n",
    "                    fin_times[stack_node-1] = time\n",
    "                    time += 1\n",
    "    \n",
    "    return fin_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rearrange nodes in decresing finishing times order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeNodesByFinTimes(fin_times):\n",
    "    for i in range(num_nodes):\n",
    "        fin_times_node_order[fin_times[i]-1] = i+1\n",
    "    return fin_times_node_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DFS on direct graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfsDirectLeaders(fin_times_node_order, gr):\n",
    "    global stack\n",
    "    global visited \n",
    "    visited = [False] * len(visited)  # Resetting the visited variable\n",
    "    fin_times_node_order.reverse()  # The nodes should be visited in reverse finishing times\n",
    "    component_sizes = [] # list to store component sizes\n",
    "    \n",
    "    for node in fin_times_node_order:\n",
    "        component_size = 0\n",
    "        \n",
    "        if visited[node-1] == False:\n",
    "            visited[node-1] = True\n",
    "            component_size += 1\n",
    "            stack.append(node)\n",
    "            \n",
    "            while len(stack) > 0:\n",
    "                stack_node = stack.pop()\n",
    "                \n",
    "                for out_node in gr[stack_node-1]:  \n",
    "\n",
    "                    if visited[out_node-1] == False:\n",
    "                        visited[out_node-1] = True\n",
    "                        component_size +=1\n",
    "                        stack.append(out_node)\n",
    "        \n",
    "            component_sizes.append(component_size)\n",
    "    \n",
    "    return component_sizes \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final function to get 5 largest SCC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fiveMaxSCC(gr, r_gr): \n",
    "    fin_times = dfsReverseFinTimes(r_gr)\n",
    "    nodes_by_ft = arrangeNodesByFinTimes(fin_times)\n",
    "    comp_sizes = dfsDirectLeaders(nodes_by_ft, gr)\n",
    "    comp_sizes.sort(reverse = True)\n",
    "    return len(comp_sizes), comp_sizes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371762, [434821, 968, 459, 313, 211])"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run final function on data\n",
    "fiveMaxSCC(gr, r_gr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive approach to PA5 (works on small datasets only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. LOAD DATA\n",
    "def loadGraph():\n",
    "    file = open(\"../algorithms_course_code/data/pg_asmt_5_scc.txt\", 'r')\n",
    "    graph = []\n",
    "    for line in file:\n",
    "        line_split = line.split(\" \")\n",
    "        line_split_clean = line_split[:2]\n",
    "        line_split_int = [int(i) for i in line_split_clean]\n",
    "        graph.append(line_split_int)\n",
    "    file.close()    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. LOAD TEST DATA\n",
    "\n",
    "def loadGraphTest():\n",
    "    file = open(\"../algorithms_course_code/data/pg_asmt_5_scc_test_cases.txt\", 'r')\n",
    "    graph = []\n",
    "    for line in file:\n",
    "        line_strip = line.rstrip(\"\\n\")\n",
    "        line_split = line_strip.split(\" \")\n",
    "        if line_split != ['']:\n",
    "            line_split_int = [int(i) for i in line_split]\n",
    "            graph.append(line_split_int)\n",
    "    file.close()    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. TRANSFORM LIST OF EDGES INTO ADJACENCY LIST\n",
    "def edgeToAdjList(graph):\n",
    "    \n",
    "    adj_list_graph = {}\n",
    "    \n",
    "    for edge in graph: \n",
    "        # process tail node\n",
    "        try: \n",
    "            adj_list_graph[edge[0]][\"out_nodes\"].append(edge[1])     \n",
    "        except KeyError:\n",
    "            adj_list_graph[edge[0]] = {\"node_index\": edge[0], \"visited\": 0, \"f_t\": 0, \"lead\": 0, \"out_nodes\": [edge[1]]}\n",
    "        \n",
    "        # process head node\n",
    "        try: \n",
    "            adj_list_graph[edge[1]]\n",
    "        except KeyError:\n",
    "            adj_list_graph[edge[1]] = {\"node_index\": edge[1], \"visited\": 0, \"f_t\": 0, \"lead\": 0, \"out_nodes\": []}\n",
    "        \n",
    "    return adj_list_graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4910756 function calls in 7.186 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    6.402    6.402    6.933    6.933 <ipython-input-748-c16c5f1ede46>:2(edgeToAdjList)\n",
      "        1    0.253    0.253    7.186    7.186 <string>:1(<module>)\n",
      "        1    0.000    0.000    7.186    7.186 {built-in method builtins.exec}\n",
      "  4910752    0.531    0.000    0.531    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how long does it take to execute function on a particular input\n",
    "import cProfile\n",
    "cProfile.run('edgeToAdjList(gr)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. REVERSE ADJACENCY LIST\n",
    "\n",
    "def reverseAdjListGraph(adj_graph):\n",
    "    \"\"\"\n",
    "    takes as input an adjacency list and reverses edges\n",
    "    \"\"\"\n",
    "    vertex_number = len(adj_graph)\n",
    "    attributes_dict_structure = {\"node_index\": 0, \"visited\": 0, \"f_t\": 0, \"lead\": 0, \"out_nodes\": []}\n",
    "    rev_adj_graph = {i: copy.deepcopy(attributes_dict_structure) for i in range(1, vertex_number+1)}\n",
    "    \n",
    "    for i in range(1, vertex_number+1):\n",
    "        rev_adj_graph[i].update({\"node_index\": i})\n",
    "        \n",
    "        if len(adj_graph[i]['out_nodes']) != 0: \n",
    "            \n",
    "            for j in range(len(adj_graph[i]['out_nodes'])):        \n",
    "                new_node = adj_graph[i]['out_nodes'][j]\n",
    "                \n",
    "                # rev_adj_graph[new_node].update({\"node_index\": new_node})\n",
    "                rev_adj_graph[new_node]['out_nodes'].append(i)\n",
    "    return rev_adj_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FINISHING TIMES: first run of DFS loop on reverse graph\n",
    "\n",
    "def _dfsFinTimes(adj_list_graph, node):\n",
    "    # mark i as explored\n",
    "    adj_list_graph[node][\"visited\"] = 1                       \n",
    "\n",
    "    # for every j of edges (node, j):\n",
    "    for out_node in adj_list_graph[node][\"out_nodes\"]:        \n",
    "        # if j unexplored\n",
    "        if adj_list_graph[out_node][\"visited\"] == 0:  \n",
    "            # DFS(G,j)\n",
    "            _dfsFinTimes(adj_list_graph, out_node)            \n",
    "     \n",
    "    global number_of_nodes_processed\n",
    "    number_of_nodes_processed += 1\n",
    "    \n",
    "    # add finishing time to a node of a graph\n",
    "    adj_list_graph[node][\"f_t\"] = number_of_nodes_processed   \n",
    "\n",
    "def _dfsLoopFinTimes(adj_list_graph):       \n",
    "    # for i from n down to 1\n",
    "    i = len(adj_list_graph) \n",
    "    while i > 0:                                             \n",
    "        # if i not yet explored\n",
    "        if adj_list_graph[i][\"visited\"] == 0:                \n",
    "            # DFS(G, i)\n",
    "            _dfsFinTimes(adj_list_graph, i)                          \n",
    "        i -= 1\n",
    "        \n",
    "    # create a list of fin_times keys\n",
    "    fin_time_keys = [adj_list_graph[node][\"f_t\"] for node in adj_list_graph.keys()]  \n",
    "    return fin_time_keys\n",
    "\n",
    "def finishingTimesRevGraphRecursion(adj_list_graph):\n",
    "    global number_of_nodes_processed\n",
    "    number_of_nodes_processed = 0  \n",
    "    return _dfsLoopFinTimes(adj_list_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. LEADERS AND THEIR SIZES: second run of DFS loop on direct graph with vertcies replaced by finishing times\n",
    "\n",
    "def _dfsLeadersCounter(adj_list_graph, node):\n",
    "    # global current_dfs_vertex\n",
    "    global component_size\n",
    "    \n",
    "    # mark i as explored\n",
    "    adj_list_graph[node][\"visited\"] = 1                               \n",
    "    adj_list_graph[node][\"lead\"] = current_dfs_vertex \n",
    "    component_size +=1\n",
    "       \n",
    "    # for every j of edges (node, j):\n",
    "    for new_out_node in adj_list_graph[node][\"new_out_nodes\"]:        \n",
    "        # if j unexplored \n",
    "        if adj_list_graph[new_out_node][\"visited\"] == 0:                        \n",
    "            # DFS(G,j)\n",
    "            _dfsLeadersCounter(adj_list_graph, new_out_node)         \n",
    "     \n",
    "    return adj_list_graph\n",
    "\n",
    "def dfsLoopLeadersCompSizes(adj_list_graph):    \n",
    "    rev_num_leaders = []\n",
    "    component_sizes = []   \n",
    "    \n",
    "    # for i from n down to 1\n",
    "    i = len(adj_list_graph)    \n",
    "    while i > 0:                                \n",
    "        # if i not yet explored\n",
    "        if adj_list_graph[i][\"visited\"] == 0:    \n",
    "            \n",
    "            global current_dfs_vertex\n",
    "            current_dfs_vertex = i\n",
    "            \n",
    "            global component_size\n",
    "            component_size = 0\n",
    "            \n",
    "            # DFS(G, i)\n",
    "            _dfsLeadersCounter(adj_list_graph, i)               \n",
    "            \n",
    "            rev_num_leaders.append(current_dfs_vertex)\n",
    "            component_sizes.append(component_size)\n",
    "                          \n",
    "        i -= 1\n",
    "    \n",
    "    return component_sizes #, adj_list_graph # (no need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. RANDOM SELECT OF I-TH STATISTICS: to get 5 biggest SCC\n",
    "from random import randrange\n",
    "\n",
    "def _partition(x, pivot_index = 0):\n",
    "    i = 0\n",
    "    if pivot_index !=0: \n",
    "        x[0], x[pivot_index] = x[pivot_index], x[0]\n",
    "    \n",
    "    for j in range(len(x)-1):\n",
    "        if x[j+1] < x[0]:\n",
    "            x[j+1], x[i+1] = x[i+1], x[j+1]\n",
    "            i += 1\n",
    "    x[0], x[i] = x[i], x[0]\n",
    "    return x,i\n",
    "\n",
    "def RSelect(x,k):\n",
    "    if len(x) == 1:\n",
    "        return x[0]\n",
    "    else:\n",
    "        xpart = _partition(x, randrange(len(x)))\n",
    "        x = xpart[0] # partitioned array\n",
    "        j = xpart[1] # pivot index\n",
    "        if j == k:\n",
    "            return x[j]\n",
    "        elif j > k:\n",
    "            return RSelect(x[:j], k)\n",
    "        else:\n",
    "            k = k - j - 1\n",
    "            return RSelect(x[(j+1):], k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. FINAL FUNCTION TO GET LARGEST SCC\n",
    "def kosarajuCount(dir_graph_ed):\n",
    "    \n",
    "    # transform direct edges list into adj list\n",
    "    dir_graph_aj = edgeToAdjList(dir_graph_ed)\n",
    "    \n",
    "    # reverse direct adj list graph \n",
    "    rev_graph_aj = reverseAdjListGraph(dir_graph_aj)\n",
    "    \n",
    "    # first DFS-Loop run on reverse graph\n",
    "    # number_of_nodes_processed = 0\n",
    "    fin_time_keys = finishingTimesRevGraphRecursion(rev_graph_aj)  \n",
    "    \n",
    "    # add finishing times to direct graph attribures list and mark nodes unvisited\n",
    "    # add new out_nodes which are old ones mapped to finishing times\n",
    "    for i in range(1, len(fin_time_keys) + 1):\n",
    "        dir_graph_aj[i]['visited'] = 0\n",
    "        dir_graph_aj[i]['f_t'] = fin_time_keys[i-1]\n",
    "        dir_graph_aj[i]['new_out_nodes'] = []\n",
    "        for j in range(len(dir_graph_aj[i]['out_nodes'])):\n",
    "            old_node = dir_graph_aj[i]['out_nodes'][j]\n",
    "            dir_graph_aj[i]['new_out_nodes'].append(fin_time_keys[old_node-1])\n",
    "    \n",
    "    # replace keys in dir_graph_aj by finishing times\n",
    "    dir_graph_aj_fin_times = {}\n",
    "    for i in range(1, len(fin_time_keys) + 1):\n",
    "        ft_key = fin_time_keys[i-1]\n",
    "        dir_graph_aj_fin_times[ft_key] = dir_graph_aj[i]\n",
    "    \n",
    "    # second DFS-Loop run on direct graph      \n",
    "    component_sizes_unsorted = dfsLoopLeadersCompSizes(dir_graph_aj_fin_times)\n",
    "    \n",
    "    # use randomized selection to find 5 largest components\n",
    "    five_biggest_scc = []\n",
    "    for i in range(1,6):\n",
    "        if len(component_sizes_unsorted) >= i:\n",
    "            ord_stat = len(component_sizes_unsorted) - i\n",
    "            size = RSelect(component_sizes_unsorted, ord_stat)\n",
    "            five_biggest_scc.append(size)\n",
    "        else:\n",
    "            five_biggest_scc.append(0)\n",
    "    \n",
    "    return five_biggest_scc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = loadGraphTest()\n",
    "test2 = copy.deepcopy(test1)\n",
    "for_second = kosarajuCount(test2)\n",
    "for_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempts to increase recursion depth did not give results, core is dying\n",
    "\n",
    "import resource, sys, threading\n",
    "sys.setrecursionlimit(2 ** 20)\n",
    "#resource.setrlimit(resource.RLIMIT_STACK, (2**29,-1))\n",
    "threading.stack_size(67108864)\n",
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Dijkstra's shortest-path algorithm  \n",
    "\n",
    "* works in any directed graph with non-negative edge lengths\n",
    "* computes the shortest paths from a source vertex to all other vertices \n",
    "* very fast implementation that uses a heap data structure\n",
    "\n",
    "**[Algorithm]**\n",
    "* Input: \n",
    "    * directed (for undirected cosmetcic changes required) graph G = (V,E) (m = |E|, n = |V|)\n",
    "    * Each edge has non-negative length l_e\n",
    "    * source vertex s\n",
    "* Output: for each v belonging to V, compute L(v) = length of a shortest path s-v in G (ie sum of edge lengths)\n",
    "* Assumptions\n",
    "    * [For convinience]: assume that there is a directed path from S to every other vertex V in the graph, otherwise the shortest path distance is something we define to be plus infinity\n",
    "        * we can always detect which vertices are not reachable from S just in a preprocessing step using BFS or DFS, and then delete the irrelevant part of the graph\n",
    "        * Alternatively, Dijkstra's algorithm will quite naturally figure out what vertices there are paths to from S and which ones there are not, so this won't really come up. \n",
    "    * [Important]: we always focus on graphs where every length is non-negative (l_e >= 0 for any Ñƒ belonging to E)\n",
    "        * paths can be thought of as more abstractly as a just sequence of decisions. \n",
    "        * for example, maybe you're engaging in financial transactions and you have the option of both buying and selling assets at different times. \n",
    "        * If you sell then you get some kind of profit and that would correspond to a negative edge length. \n",
    "        * So there are quite interesting applications in which negative edge lengths are relevant. \n",
    "        * If you are dealing with such an application, Dijkstra's algorithm is not the algorithm to use. \n",
    "        * But the most well-known dealing with such problems is called Bellman-Ford\n",
    "* BFS also calculates shoretest pathÐ±Ð¸Ð³Ðµ only for a special case when length of every edge is = 1\n",
    "    * Say you have an edge that has length three. \n",
    "    * Why not just replace all the edges with a path of edges of the appropriate length? \n",
    "    * Now we have a network in which every edge has unit length and now we can just run breadth-first search. \n",
    "    * => Computing shortest paths with general edge weights reduces to computing shortest paths with unit edge weights? \n",
    "        * First comment: if all of the edge lengths were just small numbers, like 1, 2, and 3 and so on, this trick would work fine.\n",
    "        * The issue is when you have a network where the different edges can have very different lengths. \n",
    "        * If you start wantonly replacing single edges with these really long paths, you've blown up the size of your graph way too much. \n",
    "        * Even though BFS runs in linear time, it's now on this much larger graph. \n",
    "        * We'd prefer something which is linear time or almost linear time that works directly on the original graph. \n",
    "        * And that is exactly what Dijkstra's shortest-path algorithm is going to accomplish.\n",
    "\n",
    "Algorithm:\n",
    "* One loop, in each iteration of the loop we will compute the shortest path distance to one additional vertex. \n",
    "* And by the end of the loop we'll compute shortest path distances to everybody \n",
    "* If all of the edge lengths are equal to one, Dijkstra's algorithm becomes breadth-first search\n",
    "* Dijkstra's algorithm will give us our first opportunity to see the interplay between good algorithm design and good data structure design. \n",
    "    * Suitable application of the heap data structure => implementation of Dijkstra's algorithm so it runs blazingly fast, almost linear time: m * log(n).\n",
    "   \n",
    "Pseudocode:  \n",
    "* Input: G = (V,E) (m = |E|, n = |V|),  directed\n",
    "* Initialize:\n",
    "    * X = {s} [X = verticies processed so far = computed shortest path distance frot the source vertix to every vertex in X; we are goint to augment X by new vertex each iteration]\n",
    "    * A[s] = 0 [A = array to store computed shortest path distances for each vertex in X]\n",
    "    * Additional bookkeeping, which is not needed in real implementation. Just for understanding\n",
    "        * In array B we'll keep track of the shortest path itself from the source vertex s to each destination v\n",
    "        * B[s] = empty path [B = array to store computed shortest paths]\n",
    "* Main loop:\n",
    "    * while X â‰  V: [need to grow X by one node]\n",
    "        * [X = [s, ..., ..., ...]; V-X  = [..., ..., ..., ...]]\n",
    "        * [We are interested in edges crossing from X to V-X]\n",
    "        * [We scan through all those edges, one of them will lead us to the next vertex]\n",
    "        * Among all crossing edges (v, w) belonging to E with v belongong to X and w belonging to !X\n",
    "            * pick the one that minimizes A[v] + l_vw [Dijkstra's gready criterion], [call it (v*, w*)]\n",
    "            * [A[v] is already computed in earlier step]\n",
    "        * add w* to X\n",
    "        * set A[w*] == A[v*] + l_v*w*\n",
    "            * [A[v*] is already computed in earlier step]\n",
    "        * set B[w*] == B[v*] updated by (v*, w*)\n",
    "        \n",
    "**[Non-Example]**  \n",
    "* Directed graph\n",
    "    * (s, v) = 1\n",
    "    * (s, t) = -2\n",
    "    * (v, t) = -5\n",
    "* Why can't we just reduce shortest path computation with negative edge lengths to the problem of computing shortest paths with non-negative edge lengths?\n",
    "    * For example we could just add a big number to all the edges, that makes them all non-negative and then we just run Dijkstra's algorithm\n",
    "    * The issue is that different paths between a common origin and destination have differing numbers of edges. \n",
    "        * So, some might have five edges, some might have two edges. \n",
    "        * Now, if you add 10 to every single edge in the graph, you're going to change path lengths by different amounts. \n",
    "        * If a path has five edges, it's going to go up by 50 when you add 10 to every edge. \n",
    "        * If a path has only two edges, it's only going to go up by 20 when you add 10 to every edge\n",
    "        * you might actually screw up which path is the shortest\n",
    "    * Also: the straight forward Dijkstra's algorithm (without addition of large number) will be also incorrect\n",
    "    \n",
    " \n",
    "**[Proof of correctness]**  \n",
    "* Theorem: For every directed graph with non negative egde lengths, Dijkstra's algorithm correctly computes all shortest path distances [ie A[v] = L(v) for every v belonging to V; A[v] = computed shortest path, L(v) = true shortest path distance from s to v]\n",
    "\n",
    "Proof by induction: on the number of iterations\n",
    "* Base case A[s] = L(s) = 0 (correct: here we're using the fact that there are no edges with negative edge length. That makes it obvious that sort of having a non empty path can get you negative edge length better than 0)\n",
    "* Inductive step: \n",
    "    * Inductive hypothises: all previous iterations correct <=> for all v belonging to X:\n",
    "        * A[v] = L(v) and\n",
    "        * B[v] is a true shortest s-v path in G\n",
    "    * In current iteration: \n",
    "        * we pick an edge (v*, w*)\n",
    "        * we add w* to X\n",
    "        * we set B[w*] = B[v*] appended by (v*,w*)\n",
    "            * By induciton:\n",
    "            * B[v*] has length L(v*) = \n",
    "            * B[w*] has length L(v*) + l_v*w*\n",
    "        * Also: A[w*] = A(v*) + l_v*w*\n",
    "            * By the inductive hypothises A[v*] = L(v*)\n",
    "            * =>  A[w*] = L(v*) + l_v*w*\n",
    "        * Upshot: in current iteration we set:\n",
    "            * (1) A[w*] = L(v*) + l_v*w*\n",
    "            * (2) B[w*] = an s to w* path with length  A[w*]\n",
    "    * To finish proof: need to show that every s-w* path has length >= L(v*) + l_v*w* (id so pur path is the shortest)\n",
    "        * So let P = any s to w* path\n",
    "        * Any such path crosses the fronteer explored (X)/unexplored (!X) because s by def is in X, and we choose w* in !X\n",
    "        * Probably even several times. Let's look at the first time it crosses the fronteer\n",
    "        * Let it be via an edge (y, z): s >>> y > z >>> w* (z in !X, y in X)\n",
    "            * s >>> y path is in X: at least as long as shortest path: L(y) (by def) = A[y] (= by inductive hyp)\n",
    "            * y > z: length l_yz\n",
    "            * The final part z >>> w*  if it's non empty, it has a nonnegative length: >= 0 (since no negative edges)\n",
    "            * path s >>> y\n",
    "        * Total length of path P >= A[y] + l_yz\n",
    "            * earlier we selected vertex w* according to Dijkstra's greedy criterion: A[v*] + l_v*w*\n",
    "            * by Dijkstra's greedy criterion: A[y] + l_yz >= A[v*] + l_v*w* \n",
    "            * => length of some path P is >= length of out path\n",
    "            \n",
    "        \n",
    "**[Implementation]**            \n",
    "* The straight forward implementation of this algorithm is O(m*n)\n",
    "    * n-1 iterations in a while loop (we sucked all verticies into the X)\n",
    "    * Within a loop: \n",
    "        * we do naively a linear scan through all of the edges. \n",
    "        * We go through the edges. \n",
    "        * We check if it's an eligible edge, that is if its tail is in X and its head is outside of X. \n",
    "        * We can keep track of that just by having an auxiliary boollian variable for each vertex remembering whether it's an X or not. \n",
    "        * And then amongst all of the illegible edges by exhaustive search we remember which edge has the smallest Dijkstra store\n",
    "* But we can do better by organizing data: heap\n",
    "    * what's the clue that indicates that a data structure might be useful in speeding up Dijkstra's shortest path algorithm. \n",
    "    * And the way you'd figure this out is to understand where is all this work coming from\n",
    "        * Why are we doing a linear amount of work in the edges for a linear number in the vertices iterations? \n",
    "        * Well, at each iteration of this while loop we're just doing an exhaustive search to compute a minimum. \n",
    "        * We look at every edge, we look at those that cross the frontier, and we compute the one with the minimum Dijkstra score. \n",
    "        * Is there some data structure which whose reason for being is in fact to perform fast minimum computations? \n",
    "        * It's the heap data structure\n",
    "    * Heap: perform Insert, Extract min in O(logn) time\n",
    "        * logically thought of as a complete balanced binary tree, even though they are usually implemented as a laid-out linear array. \n",
    "        * height of tree approx log_2(n)\n",
    "        * And the key property that you also have to maintain is that every node the key at that node has to be at least as small as that of both of the children. \n",
    "        * This property ensures that the smallest key of them all has to be at the root of this tree\n",
    "            * extract-min â€“ by swapping up last leaf, bubbling down\n",
    "            * insert â€“ via bubbling up\n",
    "            * delete â€“ bubble up or down as needed\n",
    "        * All these operations performaed in O(log(n)) time\n",
    "\n",
    "How to use heaps? 2 Invariants:\n",
    "* Invariant 1: elements in heap = verticies of V-X\n",
    "    * when we extract them in from the heap, it'll tell us which is the next vertex to add into the set capital X\n",
    "* Invariant 2: for v belonging to V-X, key[v] = smallest Dijkstra gready score of an edge (u, v) belonging to E with u belonging to X and v belonging to X\n",
    "    * NB: Dijkstra gready score of an edge (u, v) = min(A[u] + l_uv\n",
    "    * in case when 2 edges arrive to a head vertex, we pick for score of the vertex the one which gives min gready score\n",
    "    * for vertex outside of X that doesn't have any eligible edges terminating at it, we think of the key as being plus infinity\n",
    "*  if we can successfully maintain these two invariants, then, when we extract min from this heap, we'll get exactly the correct vertex, w* star, that we're supposed to add to the set capital X next\n",
    "* Shortest path A[w*] will be the key of w* \n",
    "\n",
    "How to maintain these invariants without doing too much work?\n",
    "* invariant 1: will really take care of itself. By definition the vertices which remain in the heap are those that we haven't processed yet, and those are the ones that are outside of capital X. \n",
    "* invariant 2: \n",
    "    * a tricky problem. \n",
    "        * think about this shortest path algorithm at some intermediate iteration. \n",
    "        * A bunch of vertices have already been added to X. \n",
    "        * A bunch of vortices are still hanging out in the heap. They haven't been added to X. \n",
    "        * There's some frontier\n",
    "        * there are crossing edges, possibly in both directions. \n",
    "        * And suppose at the end of a current iteration we identify the vortex W, which we're going to extract from the heap and conceptually add to the set X. \n",
    "        * Now the reason things complicated is when we move a vertex from outside X to inside X, the frontier between X and V minus X changes. \n",
    "        * then the edges which cross the frontier change. \n",
    "        * there might be some edges which used to cross the frontier and now don't. \n",
    "        * Those are the ones that are coming into W. There is no problem here\n",
    "        * there are edges which used to not be crossing the frontier but now they are crossing the frontier. \n",
    "        * And those are precisely the edges sticking out of W. \n",
    "        * To see why it's tricky let's remember what invariant number two says. \n",
    "            * for every vertex which is still in the heap, which is not yet in X, the key for that vertex better be The smallest Dijkstra Grady score of any edge which comes from capital X and sticks into this vertex of V-X. \n",
    "            * Now in moving one vertex into X, namely this vertex w, now there can be new edges sticking into vertices which were still on the heap. \n",
    "            * As a result, the appropriate key value for vertices in the heap might become smaller than already assigned one\n",
    "       * => we need to update keys of verticies remaining in V-X\n",
    "       * but this damage is local:  the vertices whose keys we need to update are at the head of edges that stick out of W.  \n",
    "    * when w extracted fro the heap (ie added to X), \n",
    "        * for each edge (w, v) belonging to E:\n",
    "            * if v belongs to V - X (ie in the heap)\n",
    "                * delete v from the heap\n",
    "                * recompute key(v] = min[key[v], A[w] + l_wv]\n",
    "                * re-insert v to the heap\n",
    "\n",
    "**[Running time]**\n",
    "* You check: the main work is by heap operations (O(log(n)) each) \n",
    "    * we extract mins once per iteration of a while loop = (n-1) of a while loops\n",
    "    * this triggers key updates to maintain invariant 2: deletion of an element followed by insertion \n",
    "        * it seems like a vertex could trigger as many as N-1 key updates, which is Theta(n) operations. \n",
    "        * And if we sum that up over the N iterations of the while loop that w ould give us Theta(n^2)  heap operations. \n",
    "        * So, and indeed, in dense graphs, that can be the case. \n",
    "        * But let's have an edge-centric view. \n",
    "            * For each edge at the graph, let's think about when can this be responsible for some heap operations, in particular a decrease in key in the resulting insertion and deletion. \n",
    "            * If you have an edge and it points from the vertex V to the vertex W. \n",
    "            * There's actually only one situation in which this edge is going to be responsible for a decrease in key. \n",
    "            * And that's in the case where the tail of the edge V gets sucked into the set X before the head W of this edge gets sucked into the set X. \n",
    "            * then indeed we're gonna have to decrease the key of W, \n",
    "            * But that's all that's gonna happen: V can only get sucked into X once and never gonna leave it. \n",
    "            * So it's only responsible for this single decrease in key of its head W. \n",
    "            * And that's one insertion and one deletion. \n",
    "            * And in fact, if the endpoints of this edge get sucked into X in the opposite order: if the head of this edge W gets sucked into X first that doesn't even trigger a key decrease for V, \n",
    "     * But each edge (v, w) triggers at most one Delete/Insert combo (if v added to x first) = O(m)\n",
    "         * So this means that the number of heap operations is O(n), that's for the extract mins, + O(m), that's for the insert/delete combos triggered by edges during the decreased keys.\n",
    "         * O(n+m) = O(m) since graph weakly connected \n",
    "             * because of our assumption that's there's a path to s from every other vertex. \n",
    "             * If yo u think about it that means that the graph is at least weakly connected if you picked it up it would stay together in one piece. \n",
    "             * So that means it at least contains a tree, at least an in an undirected sense, \n",
    "             * which means it contains at least N minus one edges. \n",
    "             * So we're in the case of weakly connected graphs where N dominates M. \n",
    "             * M is always as big as N at least up to a plus one. \n",
    "         * So what that means is the running time of Dijkstra's algorithm, with this heap implementation, is just a log factor larger. \n",
    "             * Remember, every heap operation takes time logarithmic. \n",
    "             * So we do a linear in M number of operations; each takes time logarithmic in N. S\n",
    "             * So the running time = O(m * lon(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem set 6  \n",
    "  \n",
    "**1. Consider a directed graph with distinct and nonnegative edge lengths and a source vertex s. Fix a destination vertex t, and assume that the graph contains at least one s-t path. Which of the following statements are true?**\n",
    "\n",
    "**(a) The shortest s-t path must include the minimum-length edge of G.**  \n",
    "**(b) The shortest (i.e., minimum-length) s-t path might have as many as nâˆ’1 edges, where n is the number of vertices.**  \n",
    "**(c) There is a shortest s-t path with no repeated vertices (i.e., a \"simple\" or \"loopless\" such path).**  \n",
    "**(d) The shortest s-t path must exclude the maximum-length edge of G**\n",
    "\n",
    "Answer: b, c\n",
    "\n",
    "**2. Consider a directed graph G with a source vertex s, a destination t, and nonnegative edge lengths. Under what conditions is the shortest s-t path guaranteed to be unique?**\n",
    "\n",
    "Answer: When all edge lengths are distinct powers of 2.\n",
    "\n",
    "**3. Consider a directed graph G=(V,E) and a source vertex s with the following properties: edges that leave the source vertex s have arbitrary (possibly negative) lengths; all other edge lengths are nonnegative; and there are no edges from any other vertex to the source s. Does Dijkstra's shortest-path algorithm correctly compute shortest-path distances (from s) in this graph?**\n",
    "\n",
    "Answer: Always (why?!)\n",
    "\n",
    "**4. Consider a directed graph G and a source vertex s. Suppose G has some negative edge lengths but no negative cycles, meaning G does not have a directed cycle in which the sum of the edge lengths is negative. Suppose you run Dijkstra's algorithm on G (with source s). Which of the following statements are true? [Check all that apply.]**\n",
    "\n",
    "**(a) It's impossible to run Dijkstra's algorithm on a graph with negative edge lengths.**  \n",
    "**(b) Dijkstra's algorithm always terminates, but in some cases the paths it computes will not be the shortest paths from ss to all other vertices.**  \n",
    "**(c) Dijkstra's algorithm might loop forever.**  \n",
    "**(d) Dijkstra's algorithm always terminates, and in some cases the paths it computes will be the correct shortest paths from ss to all other vertices.**\n",
    "\n",
    "Answer: b, d\n",
    "\n",
    "**5. Consider a directed graph G and a source vertex s. Suppose G contains a negative cycle (a directed cycle in which the sum of the edge lengths is negative) and also a path from s to this cycle. Suppose you run Dijkstra's algorithm on G (with source s). Which of the following statements are true? [Check all that apply.]**\n",
    "\n",
    "**(a) Dijkstra's algorithm might loop forever.**  \n",
    "**(b) It's impossible to run Dijkstra's algorithm on a graph with a negative cycle.**  \n",
    "**(c) Dijkstra's algorithm always terminates, and in some cases the paths it computes will be the correct shortest paths from ss to all other vertices.**  \n",
    "**(d) Dijkstra's algorithm always terminates, but in some cases the paths it computes will not be the shortest paths from s to all other vertices.**\n",
    "\n",
    "Answer: d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Problems 6\n",
    "\n",
    "**1. In lecture we define the length of a path to be the sum of the lengths of its edges.** \n",
    "**Define the bottleneck of a path to be the maximum length of one of its edges.** \n",
    "**A mininum-bottleneck path between two vertices s and t is a path with bottleneck no larger than that of any other s-t path.** \n",
    "**Show how to modify Dijkstra's algorithm to compute a minimum-bottleneck path between two given vertices. The running time should be O(mlogn), as in lecture.**\n",
    "\n",
    "\n",
    "we should replace condition A[w*] == A[v*] + l_v*w* by A[w*] == max(A[v*], l_wv)\n",
    "we stop iterate once t is processed (ie all edges of t are processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def dijkstrasBottleneck(graph, start_vertex, fin_vertex):\n",
    "    processed_verticies_indicies = []\n",
    "    \n",
    "    min_bottleneck_and_prev_vert = {vertex: [float('inf'), 0] for vertex in range(1, len(graph)+1)}\n",
    "    min_bottleneck_and_prev_vert[start_vertex] = [0, start_vertex]  \n",
    "    \n",
    "    heap_unexplored_vert = [(0, start_vertex)] # (bottleneck, vertex index)\n",
    "    \n",
    "    while len(processed_verticies_indicies) < len(graph):\n",
    "        current_min_bot, current_vertex = heapq.heappop(heap_unexplored_vert)\n",
    "        \n",
    "        # Nodes can get added to the heap multiple times. We only\n",
    "        # process a vertex the first time we remove it from the heap.\n",
    "        if current_vertex not in processed_verticies_indicies:           \n",
    "            \n",
    "            # iterate through current vertex neighbors to calculate their greedy scores (= distances) \n",
    "            for neighbor_index, edge_weight in graph[current_vertex-1].items():\n",
    "                neighbor_min_bot_neck = max(current_min_bot, edge_weight)\n",
    "                    \n",
    "\n",
    "                # Only update gready scores if it's better than any path we've already found.\n",
    "                if neighbor_min_bot_neck < min_bottleneck_and_prev_vert[neighbor_index][0]:\n",
    "                    \n",
    "                    min_bottleneck_and_prev_vert[neighbor_index][0] = neighbor_min_bot_neck\n",
    "                    min_bottleneck_and_prev_vert[neighbor_index][1] = current_vertex\n",
    "                    \n",
    "                    heapq.heappush(heap_unexplored_vert, (neighbor_min_bot_neck, neighbor_index))\n",
    "            \n",
    "            \n",
    "            # if we processed fin vertex\n",
    "            if current_vertex == fin_vertex:\n",
    "                \n",
    "                print(\"[min bottleneck, previous vertex]\")\n",
    "                return min_bottleneck_and_prev_vert[fin_vertex]\n",
    "            \n",
    "            # else mark vertex as processed\n",
    "            processed_verticies_indicies.append(current_vertex)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[min bottleneck, previous vertex]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dijkstrasBottleneck(gr_test, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: 1, 8: 2},\n",
       " {1: 1, 3: 3},\n",
       " {2: 3, 4: 1},\n",
       " {3: 1, 5: 1, 8: 2},\n",
       " {4: 1, 6: 1},\n",
       " {5: 1, 7: 5},\n",
       " {6: 5, 8: 1},\n",
       " {7: 1, 1: 2, 4: 2}]"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_test = loadGraphDistTest()\n",
    "gr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. We can do better. Suppose now that the graph is undirected. Give a linear-time (O(m)) algorithm to compute a minimum-bottleneck path between two given vertices.**\n",
    "\n",
    "**3. What if the graph is directed? Can you compute a minimum-bottleneck path between two given vertices faster than O(mlogn)?**\n",
    "\n",
    "Answers see [here](https://blog.asarkar.org/algorithms-design-analysis/hw-5-opt/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming assignment 6\n",
    "\n",
    "**In this programming problem you'll code up Dijkstra's shortest-path algorithm.**\n",
    "\n",
    "**The file contains an adjacency list representation of an undirected weighted graph with 200 vertices labeled 1 to 200. Each row consists of the node tuples that are adjacent to that particular vertex along with the length of that edge. For example, the 6th row has 6 as the first entry indicating that this row corresponds to the vertex labeled 6. The next entry of this row \"141,8200\" indicates that there is an edge between vertex 6 and vertex 141 that has length 8200. The rest of the pairs of this row indicate the other vertices adjacent to vertex 6 and the lengths of the corresponding edges.**\n",
    "\n",
    "**Your task is to run Dijkstra's shortest-path algorithm on this graph, using 1 (the first vertex) as the source vertex, and to compute the shortest-path distances between 1 and every other vertex of the graph. If there is no path between a vertex v and vertex 1, we'll define the shortest-path distance between 1 and v to be 1000000.**\n",
    "\n",
    "**You should report the shortest-path distances to the following ten vertices, in order: 7,37,59,82,99,115,133,165,188,197. You should encode the distances as a comma-separated string of integers. So if you find that all ten of these vertices except 115 are at distance 1000 away from vertex 1 and 115 is 2000 distance away, then your answer should be 1000,1000,1000,1000,1000,2000,1000,1000,1000,1000. Remember the order of reporting DOES MATTER, and the string should be in the same order in which the above ten vertices are given. The string should not contain any spaces. Please type your answer in the space provided.**\n",
    "\n",
    "**IMPLEMENTATION NOTES: This graph is small enough that the straightforward O(mn) time implementation of Dijkstra's algorithm should work fine. OPTIONAL: For those of you seeking an additional challenge, try implementing the heap-based version. Note this requires a heap that supports deletions, and you'll probably need to maintain some kind of mapping between vertices and their positions in the heap.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGraphDist():\n",
    "    '''\n",
    "    loads graph into an array of dicts\n",
    "    each index of an array corresponds to a graph vertex_index-1\n",
    "    each dict stores linked verticies with corresponding arc lengths {vert: len, vert: len, ...}\n",
    "    '''\n",
    "    file = open(\"../algorithms_course_code/data/pg_asmt_6_shortest_path.txt\", 'r')\n",
    "    graph = [{} for i in range(200)]\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        line_split = line.split(\"\\t\")\n",
    "        for pair in line_split[1:-1]:\n",
    "            pair_split = pair.split(\",\")\n",
    "            graph[i][int(pair_split[0])] = int(pair_split[1])\n",
    "        i += 1\n",
    "    file.close()    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = loadGraphDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "\n",
    "def loadGraphDistTest():\n",
    "    '''\n",
    "    loads graph into an array of dicts\n",
    "    each index of an array corresponds to a graph vertex_index-1\n",
    "    each dict stores linked verticies with corresponding arc lengths {vert: len, vert: len, ...}\n",
    "    '''\n",
    "    file = open(\"../algorithms_course_code/data/pg_asmt_6_shortest_path_test_cases.txt\", 'r')\n",
    "    graph = [{} for i in range(8)]\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        line_strip = line.rstrip(\"\\n\")\n",
    "        line_split = line_strip.split(\" \")\n",
    "        \n",
    "        if line_split != ['']:\n",
    "            for pair in line_split[1:]:\n",
    "                pair_split = pair.split(\",\")\n",
    "                graph[i][int(pair_split[0])] = int(pair_split[1])\n",
    "            i += 1\n",
    "    file.close()    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: 1, 8: 2},\n",
       " {1: 1, 3: 1},\n",
       " {2: 1, 4: 1},\n",
       " {3: 1, 5: 1},\n",
       " {4: 1, 6: 1},\n",
       " {5: 1, 7: 1},\n",
       " {6: 1, 8: 1},\n",
       " {7: 1, 1: 2}]"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_test = loadGraphDistTest()\n",
    "gr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def dijkstras(graph, start_vertex):\n",
    "    processed_verticies_indicies = []\n",
    "    distances = {vertex: float('inf') for vertex in range(1, len(graph)+1)}\n",
    "    distances[start_vertex] = 0 \n",
    "    \n",
    "    heap_unexplored_vert = [(0, start_vertex)] # (distance, vertex index)\n",
    "    \n",
    "    while len(processed_verticies_indicies) < len(graph):\n",
    "        current_distance, current_vertex = heapq.heappop(heap_unexplored_vert)\n",
    "        \n",
    "        # Nodes can get added to the heap multiple times. We only\n",
    "        # process a vertex the first time we remove it from the heap.\n",
    "        if current_vertex not in processed_verticies_indicies:           \n",
    "            \n",
    "            # iterate through current vertex neighbors to calculate their greedy scores (= distances) \n",
    "            for neighbor_index, neighbor_dist in graph[current_vertex-1].items():\n",
    "                new_neighbor_dist = current_distance + neighbor_dist\n",
    "            \n",
    "                # Only update gready scores if it's better than any path we've already found.\n",
    "                if new_neighbor_dist < distances[neighbor_index]:\n",
    "                    distances[neighbor_index] = new_neighbor_dist\n",
    "                    heapq.heappush(heap_unexplored_vert, (new_neighbor_dist, neighbor_index))\n",
    "            \n",
    "            # mark vertex as processed\n",
    "            processed_verticies_indicies.append(current_vertex)\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test case run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 4, 7: 3, 8: 2}"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dijkstras(gr_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real data run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 2971,\n",
       " 3: 2644,\n",
       " 4: 3056,\n",
       " 5: 2525,\n",
       " 6: 2818,\n",
       " 7: 2599,\n",
       " 8: 1875,\n",
       " 9: 745,\n",
       " 10: 3205,\n",
       " 11: 1551,\n",
       " 12: 2906,\n",
       " 13: 2394,\n",
       " 14: 1803,\n",
       " 15: 2942,\n",
       " 16: 1837,\n",
       " 17: 3111,\n",
       " 18: 2284,\n",
       " 19: 1044,\n",
       " 20: 2351,\n",
       " 21: 3630,\n",
       " 22: 4028,\n",
       " 23: 2650,\n",
       " 24: 3653,\n",
       " 25: 2249,\n",
       " 26: 2150,\n",
       " 27: 1222,\n",
       " 28: 2090,\n",
       " 29: 3540,\n",
       " 30: 2303,\n",
       " 31: 3455,\n",
       " 32: 3004,\n",
       " 33: 2551,\n",
       " 34: 2656,\n",
       " 35: 998,\n",
       " 36: 2236,\n",
       " 37: 2610,\n",
       " 38: 3548,\n",
       " 39: 1851,\n",
       " 40: 4091,\n",
       " 41: 2732,\n",
       " 42: 2040,\n",
       " 43: 3312,\n",
       " 44: 2142,\n",
       " 45: 3438,\n",
       " 46: 2937,\n",
       " 47: 2979,\n",
       " 48: 2757,\n",
       " 49: 2437,\n",
       " 50: 3152,\n",
       " 51: 2503,\n",
       " 52: 2817,\n",
       " 53: 2420,\n",
       " 54: 3369,\n",
       " 55: 2862,\n",
       " 56: 2609,\n",
       " 57: 2857,\n",
       " 58: 3668,\n",
       " 59: 2947,\n",
       " 60: 2592,\n",
       " 61: 1676,\n",
       " 62: 2573,\n",
       " 63: 2498,\n",
       " 64: 2047,\n",
       " 65: 826,\n",
       " 66: 3393,\n",
       " 67: 2535,\n",
       " 68: 4636,\n",
       " 69: 3650,\n",
       " 70: 743,\n",
       " 71: 1265,\n",
       " 72: 1539,\n",
       " 73: 3007,\n",
       " 74: 4286,\n",
       " 75: 2720,\n",
       " 76: 3220,\n",
       " 77: 2298,\n",
       " 78: 2795,\n",
       " 79: 2806,\n",
       " 80: 982,\n",
       " 81: 2976,\n",
       " 82: 2052,\n",
       " 83: 3997,\n",
       " 84: 2656,\n",
       " 85: 1193,\n",
       " 86: 2461,\n",
       " 87: 1608,\n",
       " 88: 3046,\n",
       " 89: 3261,\n",
       " 90: 2018,\n",
       " 91: 2786,\n",
       " 92: 647,\n",
       " 93: 3542,\n",
       " 94: 3415,\n",
       " 95: 2186,\n",
       " 96: 2398,\n",
       " 97: 4248,\n",
       " 98: 3515,\n",
       " 99: 2367,\n",
       " 100: 2970,\n",
       " 101: 3536,\n",
       " 102: 2478,\n",
       " 103: 1826,\n",
       " 104: 2551,\n",
       " 105: 3368,\n",
       " 106: 2303,\n",
       " 107: 2540,\n",
       " 108: 1169,\n",
       " 109: 3140,\n",
       " 110: 2317,\n",
       " 111: 2535,\n",
       " 112: 1759,\n",
       " 113: 1899,\n",
       " 114: 508,\n",
       " 115: 2399,\n",
       " 116: 3513,\n",
       " 117: 2597,\n",
       " 118: 2176,\n",
       " 119: 1090,\n",
       " 120: 2328,\n",
       " 121: 2818,\n",
       " 122: 1306,\n",
       " 123: 2805,\n",
       " 124: 2057,\n",
       " 125: 2618,\n",
       " 126: 1694,\n",
       " 127: 3285,\n",
       " 128: 1203,\n",
       " 129: 676,\n",
       " 130: 1820,\n",
       " 131: 1445,\n",
       " 132: 2468,\n",
       " 133: 2029,\n",
       " 134: 1257,\n",
       " 135: 1533,\n",
       " 136: 2417,\n",
       " 137: 3599,\n",
       " 138: 2494,\n",
       " 139: 4101,\n",
       " 140: 546,\n",
       " 141: 1889,\n",
       " 142: 2616,\n",
       " 143: 2141,\n",
       " 144: 2359,\n",
       " 145: 648,\n",
       " 146: 2682,\n",
       " 147: 3464,\n",
       " 148: 2873,\n",
       " 149: 3109,\n",
       " 150: 2183,\n",
       " 151: 4159,\n",
       " 152: 1832,\n",
       " 153: 2080,\n",
       " 154: 1831,\n",
       " 155: 2001,\n",
       " 156: 3013,\n",
       " 157: 2143,\n",
       " 158: 1376,\n",
       " 159: 1627,\n",
       " 160: 2403,\n",
       " 161: 4772,\n",
       " 162: 2556,\n",
       " 163: 2124,\n",
       " 164: 1693,\n",
       " 165: 2442,\n",
       " 166: 3814,\n",
       " 167: 2630,\n",
       " 168: 2038,\n",
       " 169: 2776,\n",
       " 170: 1365,\n",
       " 171: 3929,\n",
       " 172: 1990,\n",
       " 173: 2069,\n",
       " 174: 3558,\n",
       " 175: 1432,\n",
       " 176: 2279,\n",
       " 177: 3829,\n",
       " 178: 2435,\n",
       " 179: 3691,\n",
       " 180: 3027,\n",
       " 181: 2345,\n",
       " 182: 3807,\n",
       " 183: 2145,\n",
       " 184: 2703,\n",
       " 185: 2884,\n",
       " 186: 3806,\n",
       " 187: 1151,\n",
       " 188: 2505,\n",
       " 189: 2340,\n",
       " 190: 2596,\n",
       " 191: 4123,\n",
       " 192: 1737,\n",
       " 193: 3136,\n",
       " 194: 1073,\n",
       " 195: 1707,\n",
       " 196: 2417,\n",
       " 197: 3068,\n",
       " 198: 1724,\n",
       " 199: 815,\n",
       " 200: 2060}"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = dijkstras(gr, 1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2599, 2610, 2947, 2052, 2367, 2399, 2029, 2442, 2505, 3068]\n"
     ]
    }
   ],
   "source": [
    "keys = [7, 37, 59, 82, 99, 115, 133, 165, 188, 197]\n",
    "values = []\n",
    "\n",
    "for key in keys:\n",
    "    value = result.get(key)\n",
    "    values.append(value)\n",
    "    \n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
